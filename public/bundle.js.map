{"version":3,"sources":["webpack:///webpack/bootstrap 9b3a46d3a7181f077b99","webpack:///./public/js/script.js"],"names":["window","SpeechRecognition","webkitSpeechRecognition","recognition","interimResults","lang","socket","io","outputYou","document","querySelector","outputBot","addEventListener","start","console","log","e","transcript","Array","from","results","map","result","join","textContent","confidence","includes","emit","err","textContext","synthVoice","text","synth","speechSynthesis","utterence","SpeechSynthesisUtterance","speak","on","replyText","box","getElementsByClassName","innerHTML"],"mappings":";AAAA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;AACA,gDAAwC;AACxC;AACA,8CAAsC,QAAQ;AAC9C;AACA;AACA;AACA;AACA;AACA,WAAG;AACH;AACA;;;;;;;ACxEAA,OAAOC,iBAAP,GAA2BD,OAAOC,iBAAP,IAA4BD,OAAOE,uBAA9D;AACA,MAAMC,cAAc,IAAIF,iBAAJ,EAApB;AACAE,YAAYC,cAAZ,GAA6B,IAA7B;AACAD,YAAYE,IAAZ,GAAmB,OAAnB;AACA,MAAMC,SAASC,IAAf;AACA,MAAMC,YAAYC,SAASC,aAAT,CAAuB,aAAvB,CAAlB;AACA,MAAMC,YAAYF,SAASC,aAAT,CAAuB,aAAvB,CAAlB;;AAEA;AACAD,SAASC,aAAT,CAAuB,QAAvB,EAAiCE,gBAAjC,CAAkD,OAAlD,EAA2D,MAAM;AAC/DT,cAAYU,KAAZ;AACAC,UAAQC,GAAR,CAAY,eAAZ,EAA6BZ,WAA7B;AACD,CAHD;;AAKAA,YAAYS,gBAAZ,CAA6B,QAA7B,EAAuCI,KAAK;AAC1C;AACA,QAAMC,aAAaC,MAAMC,IAAN,CAAWH,EAAEI,OAAb,EAChBC,GADgB,CACZC,UAAUA,OAAO,CAAP,CADE,EAEhBD,GAFgB,CAEZC,UAAUA,OAAOL,UAFL,EAGhBM,IAHgB,CAGX,EAHW,CAAnB;AAIEf,YAAUgB,WAAV,GAAwBP,UAAxB;AACAH,UAAQC,GAAR,CAAY,iBAAiBC,EAAEI,OAAF,CAAU,CAAV,EAAa,CAAb,EAAgBK,UAA7C;;AAEA,MAAIR,WAAWS,QAAX,CAAoB,SAApB,CAAJ,EAAmC;AAC/BZ,YAAQC,GAAR,CAAY,SAAZ;AACH;AACD;AACAT,SAAOqB,IAAP,CAAY,cAAZ,EAA4BV,UAA5B;AACH,CAdD;;AAgBA;;AAEA;;AAEAd,YAAYS,gBAAZ,CAA6B,OAA7B,EAAuCgB,GAAD,IAAS;AAC7CjB,YAAUkB,WAAV,GAAwB,UAAUD,GAAlC;AACD,CAFD;;AAIA,IAAIE,aAAcC,IAAD,IAAU;AACzB,QAAMC,QAAQhC,OAAOiC,eAArB;AACA,QAAMC,YAAY,IAAIC,wBAAJ,EAAlB;AACAD,YAAUH,IAAV,GAAiBA,IAAjB;AACAC,QAAMI,KAAN,CAAYF,SAAZ;AACD,CALD;;AAOA5B,OAAO+B,EAAP,CAAU,WAAV,EAAwBC,SAAD,IAAe;AACpCR,aAAWQ,SAAX;AACAxB,UAAQC,GAAR,CAAY,OAAZ,EAAqBuB,SAArB;AACA,MAAIA,cAAc,EAAlB,EAAsBA,YAAY,oBAAZ;;AAEtB,MAAIC,MAAM9B,SAAS+B,sBAAT,CAAgC,YAAhC,EAA8C,CAA9C,CAAV;AACAD,MAAIE,SAAJ,GAAgBH,SAAhB;AACD,CAPD;;AAUA;AACA;AACA;;AAEA","file":"./public/bundle.js","sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// webpack-livereload-plugin\n \t(function() {\n \t  if (typeof window === \"undefined\") { return };\n \t  var id = \"webpack-livereload-plugin-script\";\n \t  if (document.getElementById(id)) { return; }\n \t  var el = document.createElement(\"script\");\n \t  el.id = id;\n \t  el.async = true;\n \t  el.src = \"//\" + location.hostname + \":35729/livereload.js\";\n \t  document.getElementsByTagName(\"head\")[0].appendChild(el);\n \t}());\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 9b3a46d3a7181f077b99","window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nconst recognition = new SpeechRecognition();\nrecognition.interimResults = true;\nrecognition.lang = 'tr-TR';\nconst socket = io();\nconst outputYou = document.querySelector('.output-you');\nconst outputBot = document.querySelector('.output-bot');\n\n//initiates speech recognition\ndocument.querySelector('button').addEventListener('click', () => {\n  recognition.start();\n  console.log(\"STARTING asss\", recognition)\n});\n\nrecognition.addEventListener('result', e => {\n  //console.log(e.results);\n  const transcript = Array.from(e.results)\n    .map(result => result[0])\n    .map(result => result.transcript)\n    .join('');\n    outputYou.textContent = transcript;\n    console.log('Confidence: ' + e.results[0][0].confidence);\n\n    if (transcript.includes('unicorn')){\n        console.log('Unicorn');\n    }\n    //console.log(transcript);\n    socket.emit('chat message', transcript);\n});\n\n//recognition.addEventListener('end', recognition.start);\n\n//recognition.stop();\n\nrecognition.addEventListener('error', (err) => {\n  outputBot.textContext = 'Error' + err;\n});\n\nvar synthVoice = (text) => {\n  const synth = window.speechSynthesis;\n  const utterence = new SpeechSynthesisUtterance();\n  utterence.text = text;\n  synth.speak(utterence);\n};\n\nsocket.on('bot reply', (replyText) => {\n  synthVoice(replyText);\n  console.log('reply', replyText);\n  if (replyText === '') replyText = '(Sorry, no answer)';\n\n  let box = document.getElementsByClassName('output-bot')[0];\n  box.innerHTML = replyText;\n});\n\n\n//stores to result event what was said as text\n//returns SpeechRecognitionResultsList obj including result; text will be in array.\n// confidence: privacy\n\n/*recognition.addEventListener('result', (evt) => {\n    console.log('Result has been detected.');\n\n    //let last = evt.results.length - 1;\n    let text = Array.from(evt.results)\n    .map(result => result[0])\n    .map(result => result.transcript)\n    .join('');\n\n    outputYou.textContent = text;\n    console.log('Confidence: ' + evt.results[0][0].confidence);\n\n    socket.emit('chat message', text);\n  });\n\n  /*recognition.addEventListener('speeched', () => {\n    speRec.stop();\n  });\n\n  recognition.addEventListener('error', (err) => {\n    outputBot.textContext = 'Error' + err;\n  });\n\n\n\nvar synthVoice = (text) => {\n  const synth = window.speechSynthesis;\n  const utterence = new SpeechSynthesisUtterance();\n  utterence.text = text;\n  synth.speak(utterence);\n};\n\nsocket.on('bot reply', (replyText) => {\n  synthVoice(replyText);\n\n  if (replyText === '') replyText = '(Sorry, no answer)';\n\n  outputBot.textContext = replyText;\n});*/\n\n\n\n\n// WEBPACK FOOTER //\n// ./public/js/script.js"],"sourceRoot":""}